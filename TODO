======== GENERAL REMARKS =========

Correct NA handling :: NA OP ??? results in NA (always!)
Correct character(0) and "" handling
Benchmarks
Tests


========= SETTINGS / PROPERTIES / OPTIONS =======

(++) get/set locale DONE
(++) get/set native encoding DONE



========= JOIN =======

(--) stri_join (like paste()) ALIAS stri_c


========= CASE FOLDING/LETTERS =======

(+~) stri_tolower [MG*]
(+~) stri_toupper [MG*]
(~~) stri_titlecase
(--) stri_reverse [MG*]

========= SEARCH / REPLACE / SUBSTR / REGEXP =======

(+~) stri_split_fixed [BT*]
(--) stri_split_regex
(--) stri_split_charclass

(--) stri_startswith
(--) stri_endswidh

(--) stri_locate_first (exact, case-insensitive, RuleBasedCollator)
(--) stri_locate_last
(--) stri_locate_all

(--) stri_regex_locate_first
(--) stri_regex_locate_last
(--) stri_regex_locate_all

      TRANSLITERATION (~chartr())
      The most common kind of transliterator is a script, or alphabet, 
      transliterator. For example, a Russian to Latin transliterator 
      changes Russian text written in Cyrillic characters to phonetically 
      equivalent Latin characters. It does not translate Russian to English! 
      Transliteration, unlike translation, operates on characters, without 
      reference to the meanings of words and sentences.
      stri_transliterate


      StringSearch:
       language-sensitive text searching based on the comparison
      rules defined in a RuleBasedCollator object.
      StringSearch ensures that language eccentricity can be handled,
      e.g. for the German collator, characters ß and SS will be matched 
      if case is chosen to be ignored. See the "ICU Collation Design 
      Document" for more information.
      Options are provided to handle overlapping matches. E.g. 
      In English, overlapping matches produces the result 0 and 2 
      for the pattern "abab" in the text "ababab", where else 
      mutually exclusive matches only produce the result of 0. 


========== TRIM ===========

(++) stri_trim
(++) stri_rtrim [BT]
(++) stri_ltrim [BT]
(++) stri_trim_all [BT]

========= COLLATION =======

(--) string comparison (Locale-aware)
(--) ==, != (by ==)
(--) < (by >=)
(--) > (by <=)

(--) stri_order (w. collation) Merge-sort (stable, in-place)
(--) stri_sort (by stri_order)
(--) stri_rank (by stri_order)


      The Collator class performs locale-sensitive string comparison.
   
      The following example shows how to compare two strings using 
      the Collator for the default locale.
       // Compare two strings in the default locale
       UErrorCode success = U_ZERO_ERROR;
       Collator* myCollator = Collator::createInstance(success);
       if (myCollator->compare("abc", "ABC") < 0)
       cout << "abc is less than ABC" << endl;
       else
       cout << "abc is greater than or equal to ABC" << endl;


========= WRAP / TEXT BOUNDARIES ============

(+~) stri_wrap: greedy / dynamic [BT*]


      The BreakIterator class implements methods for finding the 
      location of boundaries in text.
      Line boundary analysis determines where a text string can be 
      broken when line-wrapping. The mechanism correctly handles 
      punctuation and hyphenated words.
      Sentence boundary analysis allows selection with correct interpretation
      of periods within numbers and abbreviations, and trailing punctuation
      marks such as quotation marks and parentheses.


====== UNICODE CHARACTERS AND STRINGS, LENGTH, WIDTH =====

(--) stri_empty - check for empty string
(++) stri_numbytes [DONE]
(--) stri_length (aka stri_len)
(--) stri_width
(+~) Normalization (NFC/NFD/NFKC/NFKD)
(+~) stri_chartype
(~~) stri_charname

      Unicode Character
      Properties and Names    uchar.h, uscript.h
      
          alpha: u_isUAlphabetic(c) or u_hasBinaryProperty(c, UCHAR_ALPHABETIC)
          lower: u_isULowercase(c) or u_hasBinaryProperty(c, UCHAR_LOWERCASE)
          upper: u_isUUppercase(c) or u_hasBinaryProperty(c, UCHAR_UPPERCASE)
          punct: u_ispunct(c)
          digit: u_isdigit(c) or u_charType(c)==U_DECIMAL_DIGIT_NUMBER
          xdigit: u_isxdigit(c) or u_hasBinaryProperty(c, UCHAR_POSIX_XDIGIT)
          alnum: u_hasBinaryProperty(c, UCHAR_POSIX_ALNUM)
          space: u_isUWhiteSpace(c) or u_hasBinaryProperty(c, UCHAR_WHITE_SPACE)
          blank: u_isblank(c) or u_hasBinaryProperty(c, UCHAR_POSIX_BLANK)
          cntrl: u_charType(c)==U_CONTROL_CHAR
          graph: u_hasBinaryProperty(c, UCHAR_POSIX_GRAPH)
          print: u_hasBinaryProperty(c, UCHAR_POSIX_PRINT)



========= ENCODINGS =======

(--) native encoding to/from utf-8
(--) stri_to_utf8
(--) stri_to_native
(--) stri_to_int (utf-16? utf-8?)
(--) int_to_stri 
(++) latin1 and ascii - subsets of utf-8 (check!) DONE 
(+~) stri_ucnv (like iconv()) ALMOST DONE


      //Support for UTF-8-encoded strings in non-UTF-8 locales
      //======================================================
      //
      //Comparison is done directly unless you happen to be comparing the same
      //string in different encodings.
      //
      //nzchar and nchar(, "bytes") are independent of the encoding
      //nchar(, "char") nchar(, "width") handle UTF-8 directly, translate Latin-1
      //substr substr<-  handle UTF-8 and Latin-1 directly
      //tolower toupper chartr  translate UTF-8 to wchar, rest to current charset
      //  which needs Unicode wide characters
      //abbreviate strtrim  translate
      //
      //All the string matching functions handle UTF-8 directly, otherwise
      //translate (latin1 to UTF-8, otherwise to native).
      //
      //Support for "bytes" marked encoding
      //===================================
      //
      //nzchar and nchar(, "bytes") are independent of the encoding.
      //
      //nchar(, "char") nchar(, "width") give NA (if allowed) or error.
      //substr substr<-  work in bytes
      //
      //abbreviate chartr make.names strtrim tolower toupper give error.

      
      5.15 Character encoding issues
      
      CHARSXPs can be marked as coming from a known encoding 
      (Latin-1 or UTF-8). This is mainly intended for human-readable 
      output, and most packages can just treat such CHARSXPs as a whole. 
      However, if they need to be interpreted as characters or output at 
      C level then it would normally be correct to ensure that they are 
      converted to the encoding of the current locale: this can be done 
      by accessing the data in the CHARSXP by translateChar rather than 
      by CHAR. If re-encoding is needed this allocates memory with R_alloc 
      which thus persists to the end of the .Call/.External call unless 
      vmaxset is used.
      
      There is a similar function translateCharUTF8 which converts to 
      UTF-8: this has the advantage that a faithful translation is 
      almost always possible (whereas only a few languages can be 
      represented in the encoding of the current locale unless that is UTF-8).

      There is a public interface to the encoding marked on CHARXSXPs via

     typedef enum {CE_NATIVE, CE_UTF8, CE_LATIN1, CE_SYMBOL, CE_ANY} cetype_t;
     cetype_t getCharCE(SEXP);
     SEXP mkCharCE(const char *, cetype_t);

      Only CE_UTF8 and CE_LATIN1 are marked on CHARSXPs (and so 
      Rf_getCharCE will only return one of the first three), 
      and these should only be used on non-ASCII strings. Value 
      CE_SYMBOL is used internally to indicate Adobe Symbol encoding. 
      Value CE_ANY is used to indicate a character string that will not 
      need re-encoding – this is used for character strings known to be 
      in ASCII, and can also be used as an input parameter where the 
      intention is that the string is treated as a series of bytes. 
      (See the comments under mkChar about the length of input allowed.)

      Function
      
           const char *reEnc(const char *x, cetype_t ce_in, cetype_t ce_out,
                             int subst);
      
      can be used to re-encode character strings: like translateChar 
      it returns a string allocated by R_alloc. This can translate from 
      CE_SYMBOL to CE_UTF8, but not conversely. Argument subst controls 
      what to do with untranslatable characters or invalid input: this 
      is done byte-by-byte with 1 indicates to output hex of the form <a0>, 
      and 2 to replace by ., with any other value causing the byte 
      to produce no output.

      There is also
      
           SEXP mkCharLenCE(const char *, size_t, cetype_t);
      
      to create marked character strings of a given length. 
      
      
      Strategy for marking the encoding: if all inputs (including
      the separator) are ASCII, so is the output and we don't
      need to mark.  Otherwise if all non-ASCII inputs are of
      declared encoding, we should mark.
      
      R:
      translateChar
      translateCharUTF8
      
      Rinternals.h
      typedef enum {
          CE_NATIVE = 0,
          CE_UTF8   = 1,
          CE_LATIN1 = 2,
          CE_BYTES  = 3,
          CE_SYMBOL = 5,
          CE_ANY    =99
      } cetype_t;
      
      
         ienc = 0; CE_UTF8 CE_BYTES CE_LATIN1
      
      #define translateChar      Rf_translateChar
      #define translateChar0		Rf_translateChar0
      #define translateCharUTF8      	Rf_translateCharUTF8
      const char * Rf_translateChar(SEXP);
      const char * Rf_translateChar0(SEXP);
      const char * Rf_translateCharUTF8(SEXP);
      const char * Rf_type2char(SEXPTYPE);
      
         csep = translateChar(sep);
      	sepASCII = strIsASCII(csep);
      	sepKnown = ENC_KNOWN(sep) > 0;
      	sepUTF8 = IS_UTF8(sep);
      	sepBytes = IS_BYTES(sep);
      
      src/util.c
      Rboolean strIsASCII(const char *str)
      {
          const char *p;
          for(p = str; *p; p++)
         if((unsigned int)*p > 0x7F) return FALSE;
          return TRUE;
      }


========= BUILD ===========

* configure.in + autoconf
   - find ICU-lib dependencies
   - find ICU-lib path

* makefile.in
   - make symlinks to ICU-libs???

* Windows - Cygwin - test (PROBLEMATIC!)
